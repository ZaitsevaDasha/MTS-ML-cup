{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import scipy\n",
    "import implicit\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaMulticore\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "DATA_FOLDER = 'competition_data_final_pqt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:29<00:00,  2.96s/it]\n"
     ]
    }
   ],
   "source": [
    "all_data_agg = []\n",
    "for file in tqdm(os.listdir(DATA_FOLDER)):\n",
    "    data = pq.read_table(f'{DATA_FOLDER}/{file}')\n",
    "    data_agg = data.select(['user_id', 'url_host', 'request_cnt']).\\\n",
    "        group_by(['user_id', 'url_host']).aggregate([('request_cnt', \"sum\")])\n",
    "    all_data_agg.append(data_agg)\n",
    "\n",
    "all_data_agg = pa.concat_tables(all_data_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199683 urls\n",
      "415317 users\n"
     ]
    }
   ],
   "source": [
    "url_set = set(all_data_agg.select(['url_host']).to_pandas()['url_host'])\n",
    "print(f'{len(url_set)} urls')\n",
    "url_dict = {url: idurl for url, idurl in zip(url_set, range(len(url_set)))}\n",
    "usr_set = set(all_data_agg.select(['user_id']).to_pandas()['user_id'])\n",
    "print(f'{len(usr_set)} users')\n",
    "usr_dict = {usr: user_id for usr, user_id in zip(usr_set, range(len(usr_set)))}\n",
    "inv_usr_map = {v: k for k, v in usr_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array(all_data_agg.select(['request_cnt_sum']).to_pandas()['request_cnt_sum'])\n",
    "rows = np.array(all_data_agg.select(['user_id']).to_pandas()['user_id'].map(usr_dict))\n",
    "cols = np.array(all_data_agg.select(['url_host']).to_pandas()['url_host'].map(url_dict))\n",
    "mat = scipy.sparse.coo_matrix((values, (rows, cols)), shape=(rows.max() + 1, cols.max() + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scr_mat = mat.tocsr()\n",
    "url_data = [scr_mat[i].nonzero()[1].tolist() for i in range(scr_mat.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = implicit.approximate_als.FaissAlternatingLeastSquares(factors = 100, \\\n",
    "      iterations = 30, use_gpu = False, calculate_training_loss = False, regularization = 0.1)\n",
    "\n",
    "als.fit(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_factors = als.model.user_factors \n",
    "w_factors = als.model.item_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_usr_emb = []\n",
    "for urls in url_data:\n",
    "    vectors = w_factors[urls]\n",
    "    als_usr_emb.append(np.mean(vectors, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_embs_df = pd.DataFrame(als_usr_emb)\n",
    "als_embs_df['user_id'] = als_embs_df.index.map(inv_usr_map)\n",
    "\n",
    "als_embs_df.to_csv('embeddings/als_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = mat.astype('float').tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=600, algorithm='arpack')\n",
    "url_embeddings = svd.fit_transform(mat.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_data = [mat[i].nonzero()[1].tolist() for i in range(mat.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_usr_emb = []\n",
    "for urls in url_data:\n",
    "    vectors = url_embeddings[urls]\n",
    "    all_usr_emb.append(np.mean(vectors, axis=0))\n",
    "\n",
    "svd_embs = pd.DataFrame(all_usr_emb)\n",
    "svd_embs['user_id'] = svd_embs.index.map(inv_usr_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_embs.to_csv('embeddings/svd_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32277669it [02:50, 189809.65it/s]\n"
     ]
    }
   ],
   "source": [
    "all_data_agg = all_data_agg.to_pandas()\n",
    "\n",
    "user2urls = defaultdict(list)\n",
    "for row in tqdm(all_data_agg.itertuples(index=False)):\n",
    "    user2urls[row.user_id].extend([row.url_host] * row.request_cnt_sum)\n",
    "\n",
    "user_urls = list(user2urls.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(user_urls)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in user_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMulticore(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=50,\n",
    "    workers=8,\n",
    "    passes=20,\n",
    "    eval_every=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = lda.get_topics()\n",
    "\n",
    "all_user_emb = []\n",
    "for sites in user_urls:\n",
    "    vectors = [topics[:, dictionary.token2id[url]] for url in sites]\n",
    "    user_emb = np.mean(vectors, axis=0)\n",
    "    if isinstance(user_emb, np.float64):\n",
    "        all_user_emb.append(np.zeros((1, 50)))\n",
    "    else:\n",
    "        all_user_emb.append(user_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_embs = pd.DataFrame(all_user_emb)\n",
    "lda_embs['user_id'] = list(user2urls.keys())\n",
    "\n",
    "lda_embs.to_csv('embeddings/lda_embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DashkaConda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
